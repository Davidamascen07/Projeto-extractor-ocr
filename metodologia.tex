\chapter{Metodologia}
\label{chap:metodologia}

A metodologia adotada neste estudo tem como objetivo sistematizar o desenvolvimento, implementação e validação de um sistema de reconhecimento automatizado de padrões em comprovantes de pagamentos digitais (PIX, boletos e transferências), com base nas diretrizes definidas no TCC 1. O trabalho assume uma abordagem científica orientada à experimentação e estudo de caso, estruturada em fases bem definidas, a fim de assegurar rigor técnico, reprodutibilidade dos resultados e validação empírica da hipótese proposta.

\section{Classificação da Pesquisa}

Esta pesquisa caracteriza-se conforme os seguintes critérios metodológicos:

\begin{itemize}
    \item \textbf{Quanto à natureza:} Pesquisa aplicada
    \item \textbf{Quanto aos objetivos:} Exploratória e descritiva
    \item \textbf{Quanto à abordagem:} Quantitativa e qualitativa
    \item \textbf{Quanto aos procedimentos:} Experimental e estudo de caso
\end{itemize}

\section{Desenvolvimento do Sistema}

\subsection{Arquitetura do Sistema}

O sistema foi desenvolvido com base em uma arquitetura modular, organizada em camadas responsáveis por diferentes funções do processo de extração de dados. Essa separação facilita o versionamento, reuso de código, testes e manutenibilidade da aplicação. A comunicação entre as camadas é estruturada seguindo o fluxo: Camada de Apresentação $\rightarrow$ Camada de Processamento $\rightarrow$ Camada de ML $\rightarrow$ Camada de Dados.

O sistema implementa detecção específica para layouts de \textbf{Nubank, Will Bank, Banco Inter} e um mecanismo de fallback para layouts genéricos, permitindo maior precisão na extração de dados através do reconhecimento de padrões visuais característicos de cada instituição financeira.

\subsection{Tecnologias e Ferramentas}

A linguagem de programação utilizada foi o Python 3.8+, devido à sua ampla adoção em aplicações de Machine Learning e processamento de imagens. Para o reconhecimento óptico de caracteres (OCR), foi empregado o Tesseract OCR em conjunto com a biblioteca pytesseract, que oferece uma interface Python robusta para extração de texto de imagens. O Tesseract é uma das ferramentas de OCR mais maduras e precisas disponíveis, com suporte nativo ao idioma português.

No âmbito do Machine Learning, foram utilizadas as bibliotecas scikit-learn para algoritmos de classificação e validação, pandas para manipulação e análise de dados estruturados, e numpy para operações matemáticas e processamento de arrays. Para o processamento de imagem, empregou-se OpenCV, uma biblioteca completa para visão computacional que permite aplicação de filtros, transformações geométricas e melhorias na qualidade das imagens, complementada pela Pillow para operações básicas de manipulação de imagens.

A validação dos dados extraídos foi implementada utilizando jsonschema para validação estrutural dos dados e expressões regulares (biblioteca re) para validação de padrões específicos como CPF, CNPJ, valores monetários e datas.

\section{Metodologia de Desenvolvimento}

\subsection{Coleta e Preparação dos Dados}

Foi realizado um processo sistemático de aquisição de \textbf{104 comprovantes} reais ou simulados, nos formatos de imagens (PNG, JPEG, JPG), oriundos de diferentes instituições financeiras. Os dados foram anonimizados para garantir conformidade com a LGPD, e as imagens passaram por um pré-processamento que envolveu padronização de resolução e aplicação de filtros (binarização, remoção de ruídos, normalização de brilho e contraste).

\subsection{Implementação do OCR}

A extração do texto foi feita com a biblioteca pytesseract, utilizando uma classe modular para processamento das imagens. Foram aplicadas técnicas como segmentação por regiões de interesse (ROI), detecção automática de layouts por instituição financeira (Nubank, Will Bank, Inter e genérico) e correção de erros de OCR com expressões regulares específicas para cada tipo de campo.

\subsection{Desenvolvimento do Modelo de Machine Learning}

Dois objetivos principais foram tratados:

\begin{enumerate}[label=\alph*)]
    \item \textbf{Classificação de Documentos:} Foi desenvolvido um pipeline com \textit{TfidfVectorizer} e \textit{RandomForestClassifier} para categorizar os tipos de comprovantes.
    \item \textbf{Extração e Validação de Entidades:} Foram utilizados padrões regex específicos por tipo de campo (valor, data, CPF etc.) e a validação foi feita com \textit{JSONSchema}. Campos com falhas de leitura passaram por correção automática sempre que possível.
\end{enumerate}

\subsection{Sistema de Validação}

O desempenho do sistema foi avaliado com base em métricas específicas e detalhadas. A acurácia por campo extraído foi utilizada para medir a precisão na identificação correta de informações específicas como valores monetários, datas e documentos, com análise individual das taxas de sucesso para cada tipo de dado. O sistema calcula métricas granulares incluindo taxa de acerto por campo, confiança na extração e qualidade geral do processamento.

A precisão geral da extração fornece uma visão macro do desempenho do sistema, com taxa média de \textbf{72,4\%} de acerto geral, sendo que campos como valor monetário apresentam precisão de \textbf{95\%} e datas alcançam \textbf{90\%} de precisão. O desempenho varia significativamente entre instituições, com o Nubank apresentando os melhores resultados devido ao seu layout padronizado e alta qualidade visual dos comprovantes.

O tempo médio de processamento foi medido para avaliar a viabilidade prática do sistema em cenários reais de uso, considerando que a velocidade de processamento é crucial para aplicações comerciais. A qualidade da imagem e seu impacto na acurácia foi analisada para determinar os requisitos mínimos de resolução e nitidez necessários para garantir resultados satisfatórios.

\section{Metodologia de Testes}

\subsection{Testes Unitários}

Cada módulo da aplicação (OCR, ML, validação) foi testado isoladamente com entrada controlada e validação de saídas esperadas. O sistema implementa análise automática de qualidade da extração, verificando a consistência dos dados extraídos e gerando relatórios detalhados de performance para cada processamento.

\section{Avaliação e Validação}

Para a validação do sistema, foram utilizadas \textbf{104 imagens} de comprovantes obtidas através de três fontes principais: 35 comprovantes reais anonimizados fornecidos por voluntários da pesquisa, 40 comprovantes simulados gerados através de ferramentas de criação de documentos bancários fictícios, e 29 comprovantes obtidos de bancos de dados públicos de pesquisa acadêmica, devidamente anonimizados. Esta diversidade de fontes permitiu avaliar a robustez do sistema em diferentes cenários e qualidades de imagem.

As imagens foram categorizadas por qualidade (alta, média e baixa resolução), tipo de comprovante (PIX, boleto, transferência) e instituição financeira de origem (com foco especial em Nubank, Will Bank e Banco Inter), permitindo análises segmentadas do desempenho. Os testes foram conduzidos em ambiente controlado, com cada imagem processada individualmente e os resultados comparados manualmente com os dados reais para verificação da acurácia.

Os resultados demonstraram variação significativa na performance entre diferentes layouts, com comprovantes do Nubank alcançando as maiores taxas de precisão devido à padronização e qualidade visual, enquanto layouts genéricos apresentaram maior variabilidade nos resultados.

\section{Limitações e Considerações Éticas}

O presente estudo apresenta algumas limitações metodológicas que devem ser consideradas na interpretação dos resultados. A base de dados utilizada, composta por \textbf{104 comprovantes}, embora representativa para uma prova de conceito e validação inicial do sistema, é relativamente pequena para generalizações amplas sobre a eficácia do sistema em produção. O foco restrito ao contexto brasileiro, com comprovantes emitidos por instituições financeiras nacionais, pode limitar a aplicabilidade dos resultados para outros países com diferentes padrões de documentação bancária.

A dependência da qualidade da imagem representa uma limitação técnica significativa, uma vez que imagens com baixa resolução, borradas ou com problemas de iluminação podem comprometer drasticamente a acuracia do sistema. Adicionalmente, a ausência de comprovantes com informações manuscritas na base de dados representa uma lacuna que pode afetar a performance em cenários reais onde esse tipo de documento é comum.

Do ponto de vista ético, todas as etapas da pesquisa foram conduzidas respeitando os princípios de proteção de dados pessoais. Foi implementado um rigoroso processo de anonimização dos dados pessoais presentes nos comprovantes, removendo ou mascarando informações como nomes completos, números de contas e documentos de identificação. O sistema foi projetado para não armazenar dados bancários reais após o processamento, mantendo apenas métricas de performance e dados estatísticos agregados.

A conformidade com a Lei Geral de Proteção de Dados (LGPD) foi assegurada através da obtenção de consentimento explícito dos voluntários que forneceram comprovantes reais, da implementação de medidas de segurança para proteção dos dados durante o processamento, e da utilização prioritária de dados fictícios para testes sempre que possível. Todo o processo de coleta e utilização de dados foi documentado e auditado para garantir transparência e responsabilidade no tratamento das informações.